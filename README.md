# Humans disagree with the IoU metric

## Description
Official repository of the paper "Humans disagree with the IoU for measuring object detector localization error", 
published in ICIP 2022 ([link](https://ieeexplore.ieee.org/abstract/document/9898043)).

*The localization quality of automatic object detectors is typically evaluated by the Intersection over Union (IoU) score. 
In this work, we show that humans have a different view on localization quality. To evaluate this, we conduct a survey 
with more than 70 participants. Results show that for localization errors with the exact same IoU score, humans might 
not consider that these errors are equal, and express a preference. Our work is the first to evaluate IoU with humans 
and makes it clear that relying on IoU scores alone to evaluate localization errors might not be sufficient.*

![fig1.png](figures%2Ffig1.png)

**Fig. 1**. Left: Two localizations where the magenta box (0.5 IoU) is accepted, and the cyan box (0.3 IoU) is rejected by object detectors. Right: Two equally accepted localizations (0.5 IoU) by object detectors. Which boxes do you accept?

## Support
For technical questions and support: [o.strafforello@tudelft.nl](mailto:o.strafforello@tudelft.nl).

## Authors and acknowledgment
Ombretta Strafforello, Vanathi Rajasekar, Osman S. Kayhan, Oana Inel and Jan van Gemert.
